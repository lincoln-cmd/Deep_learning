{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 files이(가) 이미 있습니다.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100 8446k    0 8446k    0     0  3901k      0 --:--:--  0:00:02 --:--:-- 3901k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 3132k    0 3132k    0     0  2991k      0 --:--:--  0:00:01 --:--:-- 2991k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 34  878k   34  304k    0     0   258k      0  0:00:03  0:00:01  0:00:02  258k\n",
      "100  878k  100  878k    0     0   578k      0  0:00:01  0:00:01 --:--:--  578k\n"
     ]
    }
   ],
   "source": [
    "!if not exist './files' mkdir files\n",
    "!curl -L -o ./files/haarcascade_frontalface_default.xml https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "!curl -L -o ./files/haarcascade_eye.xml https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n",
    "!curl -L -o ./files/emotion_model.hdf5 https://mechasolution.vn/source/blog/AI-tutorial/Emotion_Recognition/emotion_model.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-210cab0525da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msrc_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# <class 'cv2.CascadeClassifier'> returned a result with an error set 에러가 떴을 때\n",
    "# -> cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'C:/Users/sbs/Desktop/donghun/Portfolio/files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'C:/Users/sbs/Desktop/donghun/Portfolio/files/haarcascade_eye.xml')\n",
    "\n",
    "src = cv2.imread('C:/Users/sbs/face3.jpg')\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(src_gray, 1.1, 3)\n",
    "\n",
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(src, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    face = src[y: y+h, x: x+w]\n",
    "    face_gray = src_gray[y: y+h, x: x+h]\n",
    "    eyes = eye_cascade.detectMultiScale(face_gray)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imwrite('.files/face_cascade.jpg', src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'detectMultiScale'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6a97c67b5adf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'detectMultiScale'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "help(cv2.detectMultiScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml데이터 셋을 변수에 입력\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './files/haarcascade_eye.xml')\n",
    "\n",
    "# 원하는 이미지 리드\n",
    "face = cv2.imread('./files/face.jpg')\n",
    "face_gray = cv2.cvtColor(face, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[148 146 146]\n",
      "  [148 146 146]\n",
      "  [148 146 146]\n",
      "  ...\n",
      "  [ 65  65  65]\n",
      "  [ 65  65  65]\n",
      "  [ 63  65  65]]\n",
      "\n",
      " [[148 146 146]\n",
      "  [148 146 146]\n",
      "  [148 146 146]\n",
      "  ...\n",
      "  [ 66  66  66]\n",
      "  [ 65  65  65]\n",
      "  [ 63  65  65]]\n",
      "\n",
      " [[148 146 146]\n",
      "  [148 146 146]\n",
      "  [148 146 146]\n",
      "  ...\n",
      "  [ 66  66  66]\n",
      "  [ 66  66  66]\n",
      "  [ 63  65  65]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 94  96  96]\n",
      "  [ 94  96  96]\n",
      "  [ 94  96  96]\n",
      "  ...\n",
      "  [ 52  52  52]\n",
      "  [ 52  52  52]\n",
      "  [ 48  50  50]]\n",
      "\n",
      " [[ 93  95  95]\n",
      "  [ 93  95  95]\n",
      "  [ 94  96  96]\n",
      "  ...\n",
      "  [ 52  52  52]\n",
      "  [ 51  51  51]\n",
      "  [ 48  50  50]]\n",
      "\n",
      " [[ 93  95  95]\n",
      "  [ 93  95  95]\n",
      "  [ 93  95  95]\n",
      "  ...\n",
      "  [ 49  51  51]\n",
      "  [ 48  50  50]\n",
      "  [ 47  49  49]]] [[147 147 147 ...  65  65  64]\n",
      " [147 147 147 ...  66  65  64]\n",
      " [147 147 147 ...  66  66  64]\n",
      " ...\n",
      " [ 95  95  95 ...  52  52  49]\n",
      " [ 94  94  95 ...  52  51  49]\n",
      " [ 94  94  94 ...  50  49  48]]\n"
     ]
    }
   ],
   "source": [
    "print(face, face_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225) (225, 225, 3)\n"
     ]
    }
   ],
   "source": [
    "print(face_gray.shape, face.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8ef67ba824a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 이미지를 리스트형태의 데이터로 반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaleFactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 리스트형태의 데이터로 반환\n",
    "faces = face_cascade.detectMultiScale(face_gray, scaleFactor=1.1, minNeighbors=1, minSize=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-70aa8c93f066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mf_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_gray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meyes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meye_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    }
   ],
   "source": [
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(face, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    f = face[x:x + w, y: y + h]\n",
    "    f_g = face_gray[x: x + w, y: y + h]\n",
    "    eyes = eye_cascade.detectMultiScale(f_g)\n",
    "    for ex, ey, ew, eh in eyes:\n",
    "        cv2.rectangle(eyes, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imwrite('./files/face_cascade.jpg', face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "'''\n",
    "Harr Cascade 분류기 불러오기\n",
    "'''\n",
    "# 가중치 파일 경로\n",
    "cascade_filename = 'haarcascade_frontalface_alt.xml'\n",
    "# 모델 불러오기\n",
    "cascade = cv2.CascadeClassifier(cascade_filename)\n",
    "\n",
    "'''\n",
    "Test 영상 & 사진 불러오기\n",
    "'''\n",
    "# 영상 파일\n",
    "cam = cv2.VideoCapture('')\n",
    "\n",
    "# 사진 파일\n",
    "img = cv2.imread('./files/face.jpg')\n",
    "\n",
    "# 영상 재생\n",
    "def videoDetector(cam, cascade):\n",
    "    \n",
    "    while True:\n",
    "        # 캡쳐 이미지 불러오기\n",
    "        ret, img = cam.read()\n",
    "        # 영상 압축\n",
    "        img = cv2.resize(img, dsize = None, fx = 0.75, fy = 0.75)\n",
    "        # 그레이 스케일 변환\n",
    "        gray = cv.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "# 사진 출력\n",
    "def imgDetector(img, cascade):\n",
    "    img = cv2.resize(img, dsize=None, fx=0.5, fy = 0.5)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "'''\n",
    "얼굴 탐지 알고리즘 적용\n",
    "'''\n",
    "# cascade 얼굴 탐지 알고리즘\n",
    "results = cascade.detectMultiScale(gray, scaleFactor = 1.5, minNeighbors = 5, \n",
    "                                  minSize = (20, 20))\n",
    "\n",
    "# 결과값 = 탐지된 객체의 경계상자 list\n",
    "for box in results:\n",
    "    # 좌표 추출\n",
    "    x, y, w, h = box\n",
    "    # 경계 상자 그리기\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), thickness = 2)\n",
    "    \n",
    "cv2.imshow('facenet', img)\n",
    "cv2.waitKey(10000)\n",
    "\n",
    "'''\n",
    "https://deep-eye.tistory.com/18\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지를 통한 얼굴 인식(Face detection from images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_eye.xml')\n",
    "\n",
    "src = cv2.imread('./face.jpg')\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(src_gray, 1.1, 3)\n",
    "\n",
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(src, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    face = src[x: x+w, y: y+h]\n",
    "    face_gray = src_gray[x: x+w, y: y+h]\n",
    "    eye = eye_cascade.detectMultiScale(face_gray)\n",
    "    for ex, ey, ew, eh in eye:\n",
    "        cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imwrite('./face_cascade.jpg', src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function imshow> returned NULL without setting an error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d61fcfe8892b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./face_cascade.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./face2_cascade.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m: <built-in function imshow> returned NULL without setting an error"
     ]
    }
   ],
   "source": [
    "# 두개의 이미지에서 얼굴과 눈을 인식한 후, 두 이미지의 눈을 바꾼다.\n",
    "# detect -> face, eye\n",
    "# resize\n",
    "# convert\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_eye.xml')\n",
    "\n",
    "src = cv2.imread('./face.jpg')\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(src_gray, 1.1, 3)\n",
    "\n",
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(src, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    face = src[x: x+w, y: y+h]\n",
    "    face_gray = src_gray[x: x+w, y: y+h]\n",
    "    eye = eye_cascade.detectMultiScale(face_gray)\n",
    "    for ex, ey, ew, eh in eye:\n",
    "        eye1 = cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        eye1\n",
    "        \n",
    "src2 = cv2.imread('./face2.jpg')\n",
    "src2_gray = cv2.cvtColor(src2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces2 = face_cascade.detectMultiScale(src2_gray, 1.1, 3)\n",
    "\n",
    "for x, y, w, h in faces2:\n",
    "    cv2.rectangle(src2, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    face = src[x: x+w, y: y+h]\n",
    "    face_gray = src_gray[x: x+w, y: y+h]\n",
    "    eye = eye_cascade.detectMultiScale(face_gray)\n",
    "    for ex, ey, ew, eh in eye:\n",
    "        eye2 = cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        eye2\n",
    "        \n",
    "\n",
    "        \n",
    "cv2.imwrite('./face_cascade.jpg', src)\n",
    "cv2.imwrite('./face2_cascade.jpg', src2)\n",
    "cv2.imshow(src, src2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./haarcascade_eye.xml')\n",
    "emotion_cascade = cv2.CascadeClassifier('./emotion_model.hdf5')\n",
    "\n",
    "EMOTION = [\"Angry\" ,\"Disgusting\",\"Fearful\", \"Happy\", \"Sad\", \"Surpring\", \"Neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상을 통한 얼굴 인식(Face detection from videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "movie = cv2.VideoCapture('./facevideo.mp4')\n",
    "\n",
    "# 파일이 열려있는지 확인\n",
    "if movie.isOpened() == False:\n",
    "    print('Can\\'t open the File')\n",
    "    exit()\n",
    "    \n",
    "# 윈도우 생성 및 사이즈 변경\n",
    "cv2.namedWindow('Face')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = movie.read()\n",
    "    \n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # cv2.CascadeClassifier.detectMultiScale(image, scaleFactor, minNeighbors, flags, minSize, maxSize) -> object\n",
    "    # image : 실제이미지\n",
    "    # scaleFactor : 이미지 스케일\n",
    "    # objects : 반환값. 얼굴 검출 위치와 영역 변수\n",
    "    # minNeighbors : 얼굴 검출 후보들의 갯수\n",
    "    # minSize : 가능한 최소 객체 사이즈\n",
    "    # maxSize : 가능한 최대 객체 사이즈\n",
    "    faces = face_cascade.detectMultiScale(grayframe, 1.1, 3, 0, (10, 10))\n",
    "    \n",
    "    for x, y, w, h in faces:\n",
    "        cv2.ractangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3, 4, 0)\n",
    "        \n",
    "    cv2.imshow('Face', frame)\n",
    "    \n",
    "    if cv2.waitKey(1000000):\n",
    "        break\n",
    "        \n",
    "movie.release()\n",
    "cv2.destroyWindow('Face')\n",
    "\n",
    "\n",
    "'''\n",
    "https://m.blog.naver.com/PostView.nhn?blogId=chandong83&logNo=221060014462&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width : 1280.0, height : 720.0, fps : 29.97002997002997\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'desroyAllWindows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1d46f6c1ad12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m# 윈도우 종료\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m '''\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'desroyAllWindows'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture('./facevideo.mp4')\n",
    "\n",
    "if video.isOpened() == False:\n",
    "    print('Cannot open the File')\n",
    "    exit()\n",
    "    \n",
    "title = ['window']\n",
    "\n",
    "for t in title:\n",
    "    cv2.namedWindow(t)\n",
    "    \n",
    "# 영상의 넓이, 높이, 프레임 얻기\n",
    "width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print('width : {0}, height : {1}, fps : {2}'.format(width, height, fps))\n",
    "\n",
    "# linux 계열 : DIVX, XVID, MJPG, X264, WMV1, WMV2\n",
    "# windows 계열 : DIVX\n",
    "# 저장할 비디오 코덱\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "\n",
    "# 저장할 파일 이름\n",
    "filename = 'face_cascade_video.avi'\n",
    "\n",
    "# 파일 stream 생성\n",
    "out = cv2.VideoWriter(filename, fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "# haarcascade를 통해 정면 얼굴 인식\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_eye.xml')\n",
    "\n",
    "while True:\n",
    "    # 파일에서 이미지 얻기\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        break # 더 이상 이미지가 없으면(영상이 끝나면) 종료\n",
    "        \n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grayframe, (5, 5), 0)\n",
    "    faces = face_cascade.detectMultiScale(blur, 1.1, 3, 0, (50, 50))\n",
    "    \n",
    "    for x, y, w, h in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
    "        face = frame[x: x+w, y:y+h]\n",
    "        face_gray = blur[x: x+w, y: y+h]\n",
    "        eye = eye_cascade.detectMultiScale(face_gray)\n",
    "        for ex, ey, ew, eh in eye:\n",
    "            cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 3)\n",
    "    \n",
    "    # 얼굴 인식된 이미지 화면 표시\n",
    "    cv2.imshow(title[0], frame)\n",
    "    \n",
    "    # 인식된 이미지 파일로 저장\n",
    "    out.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "# 재생 파일 종료        \n",
    "video.release()\n",
    "# 저장 파일 종료\n",
    "out.release()\n",
    "# 윈도우 종료\n",
    "cv2.desroyAllWindows()\n",
    "\n",
    "'''\n",
    "https://blog.naver.com/PostView.nhn?blogId=chandong83&logNo=221129242278&categoryNo=29&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.VideoWriter(filename, fourcc, fps, frameSize, [isColor])\n",
    "- filename : 저장할 동여상 파일 이름\n",
    "- fourcc : frame 압축 관련 4자리 코드\n",
    "- fps : 초당 저장할 프레임\n",
    "- frameSize : (가로, 세로)\n",
    "- isColor : 컬러 저장 여부\n",
    "\n",
    "cv2.GaussianBlur(img, ksize, sigmaX)\n",
    "- ksize : (width, height). width와 height는 다를 수 있지만, 양수의 홀수로 지정해야 함\n",
    "- sigmaX : Gaussian kernel standard deviation in X direction\n",
    "\n",
    "Image Smoothing의 종류 : Image Blurring, Gaussian Filtering, Median Filtering, Bilateral Filtering\n",
    "\n",
    "\n",
    "\n",
    "\"https://webnautes.tistory.com/1255\" - opencv 블러링 이론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://webnautes.tistory.com/1352 - haar특징, 원리 및 예제\n",
    "https://deep-eye.tistory.com/18 - 예제\n",
    "https://medium.com/@jsflo.dev/training-a-tensorflow-model-to-recognize-emotions-a20c3bcd6468\n",
    "- 표정 인식 설명\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
