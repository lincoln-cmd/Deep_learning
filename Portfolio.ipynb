{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 files이(가) 이미 있습니다.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100 8446k    0 8446k    0     0  3901k      0 --:--:--  0:00:02 --:--:-- 3901k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 3132k    0 3132k    0     0  2991k      0 --:--:--  0:00:01 --:--:-- 2991k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 34  878k   34  304k    0     0   258k      0  0:00:03  0:00:01  0:00:02  258k\n",
      "100  878k  100  878k    0     0   578k      0  0:00:01  0:00:01 --:--:--  578k\n"
     ]
    }
   ],
   "source": [
    "!if not exist './files' mkdir files\n",
    "!curl -L -o ./files/haarcascade_frontalface_default.xml https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "!curl -L -o ./files/haarcascade_eye.xml https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n",
    "!curl -L -o ./files/emotion_model.hdf5 https://mechasolution.vn/source/blog/AI-tutorial/Emotion_Recognition/emotion_model.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-210cab0525da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msrc_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# <class 'cv2.CascadeClassifier'> returned a result with an error set 에러가 떴을 때\n",
    "# -> cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'C:/Users/sbs/Desktop/donghun/Portfolio/files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'C:/Users/sbs/Desktop/donghun/Portfolio/files/haarcascade_eye.xml')\n",
    "\n",
    "src = cv2.imread('C:/Users/sbs/face3.jpg')\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(src_gray, 1.1, 3)\n",
    "\n",
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(src, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    face = src[y: y+h, x: x+w]\n",
    "    face_gray = src_gray[y: y+h, x: x+h]\n",
    "    eyes = eye_cascade.detectMultiScale(face_gray)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imwrite('.files/face_cascade.jpg', src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'detectMultiScale'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6a97c67b5adf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'detectMultiScale'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "help(cv2.detectMultiScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml데이터 셋을 변수에 입력\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './files/haarcascade_eye.xml')\n",
    "\n",
    "# 원하는 이미지 리드\n",
    "face = cv2.imread('./files/face.jpg')\n",
    "face_gray = cv2.cvtColor(face, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[148 146 146]\n",
      "  [148 146 146]\n",
      "  [148 146 146]\n",
      "  ...\n",
      "  [ 65  65  65]\n",
      "  [ 65  65  65]\n",
      "  [ 63  65  65]]\n",
      "\n",
      " [[148 146 146]\n",
      "  [148 146 146]\n",
      "  [148 146 146]\n",
      "  ...\n",
      "  [ 66  66  66]\n",
      "  [ 65  65  65]\n",
      "  [ 63  65  65]]\n",
      "\n",
      " [[148 146 146]\n",
      "  [148 146 146]\n",
      "  [148 146 146]\n",
      "  ...\n",
      "  [ 66  66  66]\n",
      "  [ 66  66  66]\n",
      "  [ 63  65  65]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 94  96  96]\n",
      "  [ 94  96  96]\n",
      "  [ 94  96  96]\n",
      "  ...\n",
      "  [ 52  52  52]\n",
      "  [ 52  52  52]\n",
      "  [ 48  50  50]]\n",
      "\n",
      " [[ 93  95  95]\n",
      "  [ 93  95  95]\n",
      "  [ 94  96  96]\n",
      "  ...\n",
      "  [ 52  52  52]\n",
      "  [ 51  51  51]\n",
      "  [ 48  50  50]]\n",
      "\n",
      " [[ 93  95  95]\n",
      "  [ 93  95  95]\n",
      "  [ 93  95  95]\n",
      "  ...\n",
      "  [ 49  51  51]\n",
      "  [ 48  50  50]\n",
      "  [ 47  49  49]]] [[147 147 147 ...  65  65  64]\n",
      " [147 147 147 ...  66  65  64]\n",
      " [147 147 147 ...  66  66  64]\n",
      " ...\n",
      " [ 95  95  95 ...  52  52  49]\n",
      " [ 94  94  95 ...  52  51  49]\n",
      " [ 94  94  94 ...  50  49  48]]\n"
     ]
    }
   ],
   "source": [
    "print(face, face_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225) (225, 225, 3)\n"
     ]
    }
   ],
   "source": [
    "print(face_gray.shape, face.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8ef67ba824a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 이미지를 리스트형태의 데이터로 반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaleFactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 리스트형태의 데이터로 반환\n",
    "faces = face_cascade.detectMultiScale(face_gray, scaleFactor=1.1, minNeighbors=1, minSize=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-70aa8c93f066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mf_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_gray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meyes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meye_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    }
   ],
   "source": [
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(face, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    f = face[x:x + w, y: y + h]\n",
    "    f_g = face_gray[x: x + w, y: y + h]\n",
    "    eyes = eye_cascade.detectMultiScale(f_g)\n",
    "    for ex, ey, ew, eh in eyes:\n",
    "        cv2.rectangle(eyes, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imwrite('./files/face_cascade.jpg', face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "'''\n",
    "Harr Cascade 분류기 불러오기\n",
    "'''\n",
    "# 가중치 파일 경로\n",
    "cascade_filename = 'haarcascade_frontalface_alt.xml'\n",
    "# 모델 불러오기\n",
    "cascade = cv2.CascadeClassifier(cascade_filename)\n",
    "\n",
    "'''\n",
    "Test 영상 & 사진 불러오기\n",
    "'''\n",
    "# 영상 파일\n",
    "cam = cv2.VideoCapture('')\n",
    "\n",
    "# 사진 파일\n",
    "img = cv2.imread('./files/face.jpg')\n",
    "\n",
    "# 영상 재생\n",
    "def videoDetector(cam, cascade):\n",
    "    \n",
    "    while True:\n",
    "        # 캡쳐 이미지 불러오기\n",
    "        ret, img = cam.read()\n",
    "        # 영상 압축\n",
    "        img = cv2.resize(img, dsize = None, fx = 0.75, fy = 0.75)\n",
    "        # 그레이 스케일 변환\n",
    "        gray = cv.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "# 사진 출력\n",
    "def imgDetector(img, cascade):\n",
    "    img = cv2.resize(img, dsize=None, fx=0.5, fy = 0.5)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "'''\n",
    "얼굴 탐지 알고리즘 적용\n",
    "'''\n",
    "# cascade 얼굴 탐지 알고리즘\n",
    "results = cascade.detectMultiScale(gray, scaleFactor = 1.5, minNeighbors = 5, \n",
    "                                  minSize = (20, 20))\n",
    "\n",
    "# 결과값 = 탐지된 객체의 경계상자 list\n",
    "for box in results:\n",
    "    # 좌표 추출\n",
    "    x, y, w, h = box\n",
    "    # 경계 상자 그리기\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), thickness = 2)\n",
    "    \n",
    "cv2.imshow('facenet', img)\n",
    "cv2.waitKey(10000)\n",
    "\n",
    "'''\n",
    "https://deep-eye.tistory.com/18\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_eye.xml')\n",
    "\n",
    "src = cv2.imread('./face.jpg')\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(src_gray, 1.1, 3)\n",
    "\n",
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(src, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    face = src[x: x+w, y: y+h]\n",
    "    face_gray = src_gray[x: x+w, y: y+h]\n",
    "    eye = eye_cascade.detectMultiScale(face_gray)\n",
    "    for ex, ey, ew, eh in eye:\n",
    "        cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        \n",
    "cv2.imwrite('./face_cascade.jpg', src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./haarcascade_eye.xml')\n",
    "emotion_cascade = cv2.CascadeClassifier('./emotion_model.hdf5')\n",
    "\n",
    "EMOTION = [\"Angry\" ,\"Disgusting\",\"Fearful\", \"Happy\", \"Sad\", \"Surpring\", \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://webnautes.tistory.com/1352 - haar특징, 원리 및 예제\n",
    "https://deep-eye.tistory.com/18 - 예제\n",
    "https://medium.com/@jsflo.dev/training-a-tensorflow-model-to-recognize-emotions-a20c3bcd6468\n",
    "- 표정 인식 설명\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
